{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-06-25 23:07:16.264552: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n","2022-06-25 23:07:16.264574: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"]}],"source":["import tensorflow as tf\n","from keras.layers import Conv2D, Flatten, UpSampling2D, InputLayer\n","from keras.models import Sequential\n","from tensorflow.keras.utils import array_to_img, img_to_array, load_img\n","import numpy as np\n","import cv2 as cv\n","import os"]},{"cell_type":"markdown","metadata":{},"source":["## Loading images and preprocess"]},{"cell_type":"code","execution_count":123,"metadata":{},"outputs":[],"source":["# load all images from a directory\n","def load_images(path):\n","    images = []\n","    x = 0\n","    for filename in os.listdir(path):\n","        if x <= 50:\n","            img = cv.imread(os.path.join(path, filename))\n","            img = cv.resize(img, (256, 256))\n","            if img is not None:\n","                images.append(img)\n","            x += 1\n","    return images"]},{"cell_type":"code","execution_count":124,"metadata":{},"outputs":[],"source":["imgs = load_images('./input/img')"]},{"cell_type":"code","execution_count":125,"metadata":{},"outputs":[],"source":["# convert to numpy array\n","imgs = np.array(imgs)\n","\n","#convert a list of images to lab \n","lab_images = np.array([cv.cvtColor(np.float32(1.0/255*imgs[i]), cv.COLOR_BGR2LAB) for i in range(len(imgs))])\n","\n","#get the L channel\n","l_images = np.array([np.float32(lab_images[i][:, :, 0]) for i in range(len(lab_images))])\n"]},{"cell_type":"code","execution_count":126,"metadata":{},"outputs":[{"data":{"text/plain":["(51, 256, 256)"]},"execution_count":126,"metadata":{},"output_type":"execute_result"}],"source":["l_images.shape"]},{"cell_type":"code","execution_count":127,"metadata":{},"outputs":[{"data":{"text/plain":["(51, 256, 256, 2)"]},"execution_count":127,"metadata":{},"output_type":"execute_result"}],"source":["#get the A and B channels\n","ab_images = np.array([np.float32(lab_images[i][:, :, 1:]) for i in range(len(lab_images))])\n","ab_images /= 128\n","ab_images.shape"]},{"cell_type":"code","execution_count":129,"metadata":{},"outputs":[{"data":{"text/plain":["(51, 256, 256, 1)"]},"execution_count":129,"metadata":{},"output_type":"execute_result"}],"source":["l_images = l_images.reshape(51,256,256,1)\n","l_images.shape"]},{"cell_type":"markdown","metadata":{},"source":["## Model"]},{"cell_type":"code","execution_count":110,"metadata":{},"outputs":[],"source":["# Building the neural network\n","def buildSimpleNN():\n","    model = Sequential()\n","    model.add(InputLayer(input_shape=(None, None, 1)))\n","    model.add(Conv2D(8, (3, 3), activation='relu', padding='same', strides=2))\n","    model.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n","    model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n","    model.add(Conv2D(16, (3, 3), activation='relu', padding='same', strides=2))\n","    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n","    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', strides=2))\n","    model.add(UpSampling2D((2, 2)))\n","    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n","    model.add(UpSampling2D((2, 2)))\n","    model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n","    model.add(UpSampling2D((2, 2)))\n","    model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))\n","\n","    model.compile(optimizer='rmsprop', loss='mse')\n","\n","    return model"]},{"cell_type":"markdown","metadata":{},"source":["## Training model"]},{"cell_type":"code","execution_count":149,"metadata":{},"outputs":[],"source":["X = l_images.astype(np.float32)\n","Y = ab_images.astype(np.float32)"]},{"cell_type":"code","execution_count":152,"metadata":{},"outputs":[],"source":["# Training the neural network\n","def trainModel(X, Y, model):\n","    print('Training model...')\n","    model.fit(x=X, y=Y, batch_size=1, epochs=30, verbose=1)\n","    print('Model trained.')"]},{"cell_type":"code","execution_count":153,"metadata":{},"outputs":[],"source":["model = buildSimpleNN()"]},{"cell_type":"code","execution_count":154,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training model...\n","Epoch 1/30\n","51/51 [==============================] - 7s 99ms/step - loss: 0.0152\n","Epoch 2/30\n","51/51 [==============================] - 5s 98ms/step - loss: 0.0121\n","Epoch 3/30\n","51/51 [==============================] - 5s 100ms/step - loss: 0.0123\n","Epoch 4/30\n","51/51 [==============================] - 6s 108ms/step - loss: 0.0120\n","Epoch 5/30\n","51/51 [==============================] - 5s 98ms/step - loss: 0.0118\n","Epoch 6/30\n","51/51 [==============================] - 5s 97ms/step - loss: 0.0118\n","Epoch 7/30\n","51/51 [==============================] - 5s 95ms/step - loss: 0.0117\n","Epoch 8/30\n","51/51 [==============================] - 5s 100ms/step - loss: 0.0118\n","Epoch 9/30\n","51/51 [==============================] - 5s 104ms/step - loss: 0.0116\n","Epoch 10/30\n","51/51 [==============================] - 5s 97ms/step - loss: 0.0117\n","Epoch 11/30\n","51/51 [==============================] - 5s 98ms/step - loss: 0.0126\n","Epoch 12/30\n","51/51 [==============================] - 5s 101ms/step - loss: 0.0117\n","Epoch 13/30\n","51/51 [==============================] - 5s 104ms/step - loss: 0.0115\n","Epoch 14/30\n","51/51 [==============================] - 5s 102ms/step - loss: 0.0118\n","Epoch 15/30\n","51/51 [==============================] - 5s 98ms/step - loss: 0.0116\n","Epoch 16/30\n","51/51 [==============================] - 5s 102ms/step - loss: 0.0114\n","Epoch 17/30\n","51/51 [==============================] - 5s 101ms/step - loss: 0.0119\n","Epoch 18/30\n","51/51 [==============================] - 5s 99ms/step - loss: 0.0114\n","Epoch 19/30\n","51/51 [==============================] - 5s 102ms/step - loss: 0.0125\n","Epoch 20/30\n","51/51 [==============================] - 5s 104ms/step - loss: 0.0116\n","Epoch 21/30\n","51/51 [==============================] - 5s 105ms/step - loss: 0.0116\n","Epoch 22/30\n","51/51 [==============================] - 5s 102ms/step - loss: 0.0114\n","Epoch 23/30\n","51/51 [==============================] - 5s 101ms/step - loss: 0.0116\n","Epoch 24/30\n","51/51 [==============================] - 5s 103ms/step - loss: 0.0114\n","Epoch 25/30\n","51/51 [==============================] - 5s 104ms/step - loss: 0.0117\n","Epoch 26/30\n","51/51 [==============================] - 6s 126ms/step - loss: 0.0115\n","Epoch 27/30\n","51/51 [==============================] - 6s 126ms/step - loss: 0.0114\n","Epoch 28/30\n","51/51 [==============================] - 5s 105ms/step - loss: 0.0113\n","Epoch 29/30\n","51/51 [==============================] - 5s 101ms/step - loss: 0.0111\n","Epoch 30/30\n","51/51 [==============================] - 5s 101ms/step - loss: 0.0113\n","Model trained.\n"]}],"source":["trainModel(X, Y, model)"]},{"cell_type":"code","execution_count":155,"metadata":{},"outputs":[],"source":["from datetime import datetime\n","\n","# Save model\n","model.save('./models/model_'+datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")+'.h5')"]},{"cell_type":"markdown","metadata":{},"source":["## Prediction"]},{"cell_type":"code","execution_count":156,"metadata":{},"outputs":[],"source":["# Get the luminance of the image aka the image in black and white\n","def getLFromLab(image_loaded):\n","    L_image = cv.cvtColor(np.float32(\n","        1.0/255 * image_loaded), cv.COLOR_RGB2LAB)[:, :, 0]\n","    L_image = L_image.reshape(1,256,256, 1)\n","    return L_image"]},{"cell_type":"code","execution_count":157,"metadata":{},"outputs":[],"source":["# Get a image with colorized pixels\n","def getColorizeImage(image_name, model):\n","    #Get image data\n","    image_loaded = img_to_array(load_img(image_name))\n","    image_loaded = cv.resize(image_loaded, (256, 256))\n","    image_loaded = np.array(image_loaded, dtype=float)\n","    #Get luminosity/Black&White image\n","    L_image = getLFromLab(image_loaded)\n","    #Predict\n","    output = model.predict(L_image)\n","    output = output * 128\n","    #Transform output to image\n","    cur = np.zeros((256, 256, 3))\n","    cur[:,:,0] = L_image[0][:,:,0]\n","    cur[:,:,1:] = output[0]\n","    #Convert to BGR\n","    cv_result = cv.cvtColor(np.float32(cur),  cv.COLOR_LAB2BGR)\n","    cv_result = cv_result * 255\n","    cv_result = cv_result.round(0)\n","    result_name = './output/result_'+datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")+'.png'\n","    cv.imwrite(result_name, cv_result)\n"]},{"cell_type":"code","execution_count":160,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 39ms/step\n"]}],"source":["getColorizeImage(\"./input/images/guada.jpg\", model)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.12 ('cnn')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"1dd3dd669c9def6b0e635a9f058e218b456569432076eab3c3eac468c9cc4681"}}},"nbformat":4,"nbformat_minor":4}
